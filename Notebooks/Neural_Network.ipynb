{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer, FunctionTransformer, QuantileTransformer\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from Data_Processing import DataProcessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataProcessing('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Lap_Time'] != 0]\n",
    "\n",
    "y = df['Lap_Time']\n",
    "X = df.drop(columns=['Lap_Time'])\n",
    "\n",
    "obj_columns = list(X.select_dtypes(include=object).columns)\n",
    "obj_columns.append('Lap_Number')\n",
    "obj_columns.append('Lap_Improvement')\n",
    "\n",
    "num_columns = list(X.select_dtypes(include='number').columns)\n",
    "num_columns.remove('Lap_Number')\n",
    "num_columns.remove('Lap_Improvement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = PowerTransformer(method='yeo-johnson')\n",
    "#X[num_columns] = pt.fit_transform(X[num_columns])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "[('num', StandardScaler(), num_columns),\n",
    "('obj', OneHotEncoder(), obj_columns)],\n",
    "remainder='passthrough')\n",
    "\n",
    "trans_X = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(column_transformer, '../Models/Column_Transformer_NN.pkl')\n",
    "#joblib.dump(pt, '../Models/Power_Transformer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans_X = trans_X.toarray()\n",
    "y = np.asarray(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = X[:1000]\n",
    "plot_y = y[:1000,]\n",
    "\n",
    "test_x = trans_X[:1000,]\n",
    "test_y = y[:1000,]\n",
    "\n",
    "trans_X = trans_X[1000:,]\n",
    "y = y[1000:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trans_X, y, random_state=42, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(K.log(1+y_pred) - K.log(1+y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(f'../Models/NN_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu', input_dim=114),\n",
    "    keras.layers.LeakyReLU(500),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.LeakyReLU(800),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.LeakyReLU(200),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.Dense(200, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=root_mean_squared_log_error,\n",
    "              metrics=['mean_squared_logarithmic_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=100,\n",
    "    epochs=300,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[mc, early_stopping],\n",
    "    shuffle=True,\n",
    "    steps_per_epoch=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test = model.predict(test_x).reshape(-1)\n",
    "test_y = test_y.astype(float)\n",
    "y_predicted_test = y_predicted_test.astype(float)\n",
    "root_mean_squared_log_error(test_y, y_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Predicted'] = y_predicted_test\n",
    "results['Actual']= test_y\n",
    "results['Difference'] = abs(results['Predicted'] - results['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "mean_squared_log_error(test_y, y_predicted_test, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0093e+04, 2.9000e+01, 4.0000e+00, 3.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([0.00502513, 0.02952261, 0.0540201 , 0.07851759, 0.10301508,\n",
       "        0.12751256, 0.15201005, 0.17650754, 0.20100503, 0.22550251,\n",
       "        0.25      ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(1/df['Lap_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.73"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
